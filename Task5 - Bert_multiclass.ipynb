{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3V5ufSM9wqje",
    "outputId": "1a44da69-e48e-41a7-ca48-f4f050240200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 7.7MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 26.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 52.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=3a98a40eb658f71597c25e7aefd1ed09eb9854c90a1f664089721146e752c39a\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PDvilZ3Nce_",
    "outputId": "50b96336-a7b7-4aff-d577-f277fcb4b906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 11 18:35:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   70C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "gTsFJKO_pbjv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V3bltLA-piyD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9cBXYA6Dpi00",
    "outputId": "86757336-530f-43fc-fd29-740908dbd37d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>length_text</th>\n",
       "      <th>not_tag_text</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negative_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>@mention @mention say</td>\n",
       "      <td>22</td>\n",
       "      <td>say</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>@mention plus add commercial experience tacky</td>\n",
       "      <td>46</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>@mention today must mean need take another trip</td>\n",
       "      <td>48</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>@mention really aggressive blast obnoxious ent...</td>\n",
       "      <td>88</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>@mention really big bad thing</td>\n",
       "      <td>30</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Can't Tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  ... negative_reason\n",
       "0                @VirginAmerica What @dhepburn said.  ...             NaN\n",
       "1  @VirginAmerica plus you've added commercials t...  ...             NaN\n",
       "2  @VirginAmerica I didn't today... Must mean I n...  ...             NaN\n",
       "3  @VirginAmerica it's really aggressive to blast...  ...      Bad Flight\n",
       "4  @VirginAmerica and it's a really big bad thing...  ...      Can't Tell\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMYSdOxTrh6I"
   },
   "source": [
    "Select only positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "uNbDxJY7pi5S"
   },
   "outputs": [],
   "source": [
    "df_1 = df[['airline_sentiment','preprocessed_text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "ORPW10mUpi8U"
   },
   "outputs": [],
   "source": [
    "# Encoding target variable\n",
    "encoder = LabelEncoder()\n",
    "X = df_1['preprocessed_text']\n",
    "y = encoder.fit_transform(df_1[\"airline_sentiment\"]) #0 negative, 1  positive\n",
    "# Splitt in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "LI_5jfU26GHF"
   },
   "outputs": [],
   "source": [
    "# Transform target in tensors\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_labels = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nekumwkAsrwu"
   },
   "source": [
    "# Text Preprocessing for Bert:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start. \n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "Function *tokenizer.encode_plus* was used which encapsulates the whole procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI__7-ZMzIQ5"
   },
   "source": [
    "### FIRST - Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "k-yNyONVw9_B"
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9tXJWkjxPGH",
    "outputId": "ed95bee3-75ee-4f80-8b30-334773024d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet:  ['@', 'mention', 'travel', 'ad', '##vis', 'nyc', 'phil', 'pa', 'winter', 'weather', 'air', 'post', 'one', 'yet', 'still', 'change', 'fl', '##t', 'wo', 'pen']\n",
      "Original tweet:  @mention travel advis nyc phil pa winter weather air post one yet still change flt wo pen \n"
     ]
    }
   ],
   "source": [
    "# Example for a tweet\n",
    "print(\"Tokenized tweet: \", tokenizer.tokenize(X_train.values[0]))\n",
    "print(\"Original tweet: \", X_train.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIMMjb6Xpi-L",
    "outputId": "5b90e5ce-cf87-4ac3-af63-dd297b3a77a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  [1030, 5254, 3604, 4748, 11365, 16392, 6316, 6643, 3467, 4633, 2250, 2695, 2028, 2664, 2145, 2689, 13109, 2102, 24185, 7279]\n"
     ]
    }
   ],
   "source": [
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train.values[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "710WdazRpjAk",
    "outputId": "3872ab4b-48c2-412f-b8a5-efe41df12866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet:  ['[CLS]', '@', 'mention', 'travel', 'ad', '##vis', 'nyc', 'phil', 'pa', 'winter', 'weather', 'air', 'post', 'one', 'yet', 'still', 'change', 'fl', '##t', 'wo', 'pen', '[SEP]']\n",
      "Token IDs:  [101, 1030, 5254, 3604, 4748, 11365, 16392, 6316, 6643, 3467, 4633, 2250, 2695, 2028, 2664, 2145, 2689, 13109, 2102, 24185, 7279, 102]\n"
     ]
    }
   ],
   "source": [
    "# Example complete:\n",
    "sentence = X_train.values[0]\n",
    "tokens_ = tokenizer.tokenize(sentence)\n",
    "tokens_ = ['[CLS]'] + tokens_ + ['[SEP]']\n",
    "print(\"Tokenized tweet: \", tokens_)\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokens_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyvHTAUT0Piq"
   },
   "source": [
    "### Find MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "FblrunSFpjDB",
    "outputId": "1cf5d6fe-6b3d-43f4-a8a2-6d589d79b7ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = [len(i.split()) for i in X_train]\n",
    "test = [len(i.split()) for i in X_test]\n",
    "\n",
    "for i in [train, test]:\n",
    "  pd.Series(i).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "nKcHZJHx7lIv"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "CiAGyh6R3HcQ"
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, max_len):\n",
    "  inputs_ = []\n",
    "  attention_mask = []\n",
    "  for tweet in data:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "      tweet, #tweet to encode = (tokenize + add special character)\n",
    "      add_special_tokens = True, # Add [CLS] for specify classification task and [SEP]\n",
    "      max_length = max_len,\n",
    "      pad_to_max_length  = True, #For pad & truncate all sentence\n",
    "      return_attention_mask = True, # For return attention masks\n",
    "      #return_tensors = 'pt' # Return pythorch tensors\n",
    "    )\n",
    "    # Select encoded sentence    \n",
    "    inputs_.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Select attention masks\n",
    "    attention_mask.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  # Convert the lists into tensors.\n",
    "  input_ids = torch.tensor(inputs_)\n",
    "  attention_masks = torch.tensor(attention_mask)\n",
    "\n",
    "  return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozTBdDn77JBN",
    "outputId": "30c35b0b-dbf2-47b1-832f-88edc9e261b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_data, train_masks = prepare_data(X_train, MAX_LENGTH)\n",
    "test_data, test_masks = prepare_data(X_test, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD94OxtI8kkh",
    "outputId": "f786be94-f639-4ff3-98d3-30ce41dd21b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @mention travel advis nyc phil pa winter weather air post one yet still change flt wo pen \n",
      "Token IDs: tensor([  101,  1030,  5254,  3604,  4748, 11365, 16392,  6316,  6643,  3467,\n",
      "         4633,  2250,  2695,  2028,  2664,  2145,  2689, 13109,  2102, 24185,\n",
      "         7279,   102,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0])\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', X_train.values[0])\n",
    "print('Token IDs:', train_data[0])\n",
    "print('Attention Mask:', train_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "IcZFwZapH1Sh"
   },
   "outputs": [],
   "source": [
    "(train_inputs, validation_inputs,\n",
    " train_labels, validation_labels) = train_test_split(train_data, train_labels,\n",
    "                                                     random_state=42,\n",
    "                                                     test_size=0.1)\n",
    "(train_masks, validation_masks,\n",
    " _, _) = train_test_split(train_masks, train_data,\n",
    "                          random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiRckKHTFkrd"
   },
   "source": [
    "The DataLoader needs to know our batch size for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "_Xgm_Q9RFgos"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "kEj6_6TsF3ZO"
   },
   "outputs": [],
   "source": [
    "def dataloader(input_ids, attention_masks, labels, name):\n",
    "  dataset = TensorDataset(input_ids, attention_masks, labels) #Combine inputs in to a TensorDataset\n",
    "  if name == \"Train\":\n",
    "    sampler = RandomSampler(dataset)  # Select batches randomly\n",
    "  else:\n",
    "    sampler = SequentialSampler(dataset)  # Select batches sequentially\n",
    "  data_loader = DataLoader(\n",
    "            dataset,\n",
    "            sampler = sampler,\n",
    "            batch_size = BATCH_SIZE # Number of batchsize\n",
    "  )\n",
    "  print(f\"{name} documents {len(dataset)}\")\n",
    "  return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9sJNGKMG_x2",
    "outputId": "fe4001a1-605a-421e-aa68-e5dd4718e346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train documents 9223\n",
      "Test documents 4392\n",
      "Validation documents 1025\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataloader(train_inputs, train_masks, train_labels, \"Train\")\n",
    "test_dataloader = dataloader(test_data, test_masks, test_labels, \"Test\")\n",
    "val_dataloader = dataloader(validation_inputs, validation_masks, validation_labels, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "0ZyEtnm6VSuT"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EURfgE8lL-su"
   },
   "source": [
    "### Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E527GymlMHGh"
   },
   "source": [
    "\"bert-base-uncased\" = the 12-layer BERT model, with an uncased vocab.se the 12-layer BERT model, with an uncased vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "NkNa6RvNMCsS"
   },
   "outputs": [],
   "source": [
    "BERTMODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSSp-81yL643",
    "outputId": "db0f078d-2b90-44e0-fc9c-fa04fecbe838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    BERTMODEL, \n",
    "    num_labels = 3, # Binary classification   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRS0T3kZNQ0P"
   },
   "source": [
    "To run this model on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3gULeMNpaFY",
    "outputId": "66797dde-cd0b-47b2-f236-863d2ed1b32a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyPv7zDZPDjC"
   },
   "source": [
    "Define optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "lsNN5OG0NRyK"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "zS0N_idCQEgT"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "TSSKCkbxTnOY"
   },
   "outputs": [],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avB8dJweQuSF",
    "outputId": "149ff58d-747c-4687-9f3f-21dc50928c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      " \t Average training loss: 0.67\n",
      "  Accuracy: 0.79\n",
      "  Validation Loss: 0.53\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      " \t Average training loss: 0.49\n",
      "  Accuracy: 0.80\n",
      "  Validation Loss: 0.52\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device) #batch[0] - input_ids\n",
    "        b_input_mask = batch[1].to(device) #batch[1] - attention_masks\n",
    "        b_labels = batch[2].to(device) #batch[2] - labels\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        model.zero_grad() \n",
    "\n",
    "        # Forward pass (for evaluate the model on this training batch)\n",
    "        model1 = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels) \n",
    "        loss = model1.loss\n",
    "        logits = model1.logits\n",
    "        \n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()       \n",
    "\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)    \n",
    "\n",
    "    print(\"\\n \\t Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation PHASE \n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model2 = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss = model2.loss\n",
    "            logits = model2.logits\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "nKCjAA4nQuVP",
    "outputId": "2da6c9cc-15b4-4d9e-9483-aa25e6637c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.669025</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487169</td>\n",
       "      <td>0.518747</td>\n",
       "      <td>0.799242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur.\n",
       "epoch                                           \n",
       "1           0.669025     0.530700       0.791667\n",
       "2           0.487169     0.518747       0.799242"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 6)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqvqMcu6XrX1"
   },
   "source": [
    "Evaluation on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "mVNTqe5iQucc"
   },
   "outputs": [],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  prediction = np.argmax(logits, axis=1)\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  for i in prediction:\n",
    "    predictions.append(i)\n",
    "  for i in label_ids:\n",
    "    true_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "8AvSey-PY6E1"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(real_v, pred_v):\n",
    "    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(real_v, pred_v))\n",
    "    cm = confusion_matrix(real_v, pred_v)\n",
    "    print (f\"Confusion matrix \\n {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_MDebtnY_DM",
    "outputId": "5e6031ff-e627-45fb-bf53-ccfb70f01f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7914389799635702\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      2753\n",
      "           1       0.63      0.52      0.57       930\n",
      "           2       0.75      0.73      0.74       709\n",
      "\n",
      "    accuracy                           0.79      4392\n",
      "   macro avg       0.74      0.72      0.73      4392\n",
      "weighted avg       0.78      0.79      0.79      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2479  196   78]\n",
      " [ 352  480   98]\n",
      " [ 101   91  517]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(true_labels, predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task5 - Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
