{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3V5ufSM9wqje",
    "outputId": "1a44da69-e48e-41a7-ca48-f4f050240200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 7.7MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 26.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 52.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=3a98a40eb658f71597c25e7aefd1ed09eb9854c90a1f664089721146e752c39a\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PDvilZ3Nce_",
    "outputId": "50b96336-a7b7-4aff-d577-f277fcb4b906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 11 18:35:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   70C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "gTsFJKO_pbjv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V3bltLA-piyD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9cBXYA6Dpi00",
    "outputId": "86757336-530f-43fc-fd29-740908dbd37d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>length_text</th>\n",
       "      <th>not_tag_text</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negative_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>@mention @mention say</td>\n",
       "      <td>22</td>\n",
       "      <td>say</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>@mention plus add commercial experience tacky</td>\n",
       "      <td>46</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>@mention today must mean need take another trip</td>\n",
       "      <td>48</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>@mention really aggressive blast obnoxious ent...</td>\n",
       "      <td>88</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>@mention really big bad thing</td>\n",
       "      <td>30</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Can't Tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  ... negative_reason\n",
       "0                @VirginAmerica What @dhepburn said.  ...             NaN\n",
       "1  @VirginAmerica plus you've added commercials t...  ...             NaN\n",
       "2  @VirginAmerica I didn't today... Must mean I n...  ...             NaN\n",
       "3  @VirginAmerica it's really aggressive to blast...  ...      Bad Flight\n",
       "4  @VirginAmerica and it's a really big bad thing...  ...      Can't Tell\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMYSdOxTrh6I"
   },
   "source": [
    "Select only positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "uNbDxJY7pi5S"
   },
   "outputs": [],
   "source": [
    "df_1 = df[df[\"airline_sentiment\"]!=\"neutral\"][['airline_sentiment','preprocessed_text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "ORPW10mUpi8U"
   },
   "outputs": [],
   "source": [
    "# Encoding target variable\n",
    "encoder = LabelEncoder()\n",
    "X = df_1['preprocessed_text']\n",
    "y = encoder.fit_transform(df_1[\"airline_sentiment\"]) #0 negative, 1  positive\n",
    "# Splitt in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "LI_5jfU26GHF"
   },
   "outputs": [],
   "source": [
    "# Transform target in tensors\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_labels = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nekumwkAsrwu"
   },
   "source": [
    "# Text Preprocessing for Bert:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start. \n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "Function *tokenizer.encode_plus* was used which encapsulates the whole procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI__7-ZMzIQ5"
   },
   "source": [
    "### FIRST - Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "k-yNyONVw9_B"
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9tXJWkjxPGH",
    "outputId": "eaba4c6f-32b9-4cf3-f4b5-8fa1fb46317c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet:  ['@', 'mention', 'ok', 'may', 'keep', '@', 'number', 'lose', 'bag', 'info', 'longer', 'trust', 'bad', 'way', 'handle']\n",
      "Original tweet:  @mention ok may keep @number lose bag info longer trust bad way handle \n"
     ]
    }
   ],
   "source": [
    "# Example for a tweet\n",
    "print(\"Tokenized tweet: \", tokenizer.tokenize(X_train.values[0]))\n",
    "print(\"Original tweet: \", X_train.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIMMjb6Xpi-L",
    "outputId": "5c3c2dab-1d94-46b9-e9b0-5b880f5b7ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  [1030, 5254, 7929, 2089, 2562, 1030, 2193, 4558, 4524, 18558, 2936, 3404, 2919, 2126, 5047]\n"
     ]
    }
   ],
   "source": [
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train.values[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "710WdazRpjAk",
    "outputId": "5a74697f-957f-4554-a7db-d0e0fd91e771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet:  ['[CLS]', '@', 'mention', 'ok', 'may', 'keep', '@', 'number', 'lose', 'bag', 'info', 'longer', 'trust', 'bad', 'way', 'handle', '[SEP]']\n",
      "Token IDs:  [101, 1030, 5254, 7929, 2089, 2562, 1030, 2193, 4558, 4524, 18558, 2936, 3404, 2919, 2126, 5047, 102]\n"
     ]
    }
   ],
   "source": [
    "# Example complete:\n",
    "sentence = X_train.values[0]\n",
    "tokens_ = tokenizer.tokenize(sentence)\n",
    "tokens_ = ['[CLS]'] + tokens_ + ['[SEP]']\n",
    "print(\"Tokenized tweet: \", tokens_)\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokens_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyvHTAUT0Piq"
   },
   "source": [
    "### Find MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "FblrunSFpjDB",
    "outputId": "ddae412b-8ebf-433c-b608-3591ad16d962"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = [len(i.split()) for i in X_train]\n",
    "test = [len(i.split()) for i in X_test]\n",
    "\n",
    "for i in [train, test]:\n",
    "  pd.Series(i).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "nKcHZJHx7lIv"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "CiAGyh6R3HcQ"
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, max_len):\n",
    "  inputs_ = []\n",
    "  attention_mask = []\n",
    "  for tweet in data:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "      tweet, #tweet to encode = (tokenize + add special character)\n",
    "      add_special_tokens = True, # Add [CLS] for specify classification task and [SEP]\n",
    "      max_length = max_len,\n",
    "      pad_to_max_length  = True, #For pad & truncate all sentence\n",
    "      return_attention_mask = True, # For return attention masks\n",
    "      #return_tensors = 'pt' # Return pythorch tensors\n",
    "    )\n",
    "    # Select encoded sentence    \n",
    "    inputs_.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Select attention masks\n",
    "    attention_mask.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  # Convert the lists into tensors.\n",
    "  input_ids = torch.tensor(inputs_)\n",
    "  attention_masks = torch.tensor(attention_mask)\n",
    "\n",
    "  return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozTBdDn77JBN",
    "outputId": "193b4985-a52b-44fb-9df1-6c914cdc526b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_data, train_masks = prepare_data(X_train, MAX_LENGTH)\n",
    "test_data, test_masks = prepare_data(X_test, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD94OxtI8kkh",
    "outputId": "3dad26c8-cec6-4c24-8bd3-bf1b5232149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @mention ok may keep @number lose bag info longer trust bad way handle \n",
      "Token IDs: tensor([  101,  1030,  5254,  7929,  2089,  2562,  1030,  2193,  4558,  4524,\n",
      "        18558,  2936,  3404,  2919,  2126,  5047,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', X_train.values[0])\n",
    "print('Token IDs:', train_data[0])\n",
    "print('Attention Mask:', train_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "IcZFwZapH1Sh"
   },
   "outputs": [],
   "source": [
    "(train_inputs, validation_inputs,\n",
    " train_labels, validation_labels) = train_test_split(train_data, train_labels,\n",
    "                                                     random_state=42,\n",
    "                                                     test_size=0.1)\n",
    "(train_masks, validation_masks,\n",
    " _, _) = train_test_split(train_masks, train_data,\n",
    "                          random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiRckKHTFkrd"
   },
   "source": [
    "The DataLoader needs to know our batch size for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "_Xgm_Q9RFgos"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "kEj6_6TsF3ZO"
   },
   "outputs": [],
   "source": [
    "def dataloader(input_ids, attention_masks, labels, name):\n",
    "  dataset = TensorDataset(input_ids, attention_masks, labels) #Combine inputs in to a TensorDataset\n",
    "  if name == \"Train\":\n",
    "    sampler = RandomSampler(dataset)  # Select batches randomly\n",
    "  else:\n",
    "    sampler = SequentialSampler(dataset)  # Select batches sequentially\n",
    "  data_loader = DataLoader(\n",
    "            dataset,\n",
    "            sampler = sampler,\n",
    "            batch_size = BATCH_SIZE # Number of batchsize\n",
    "  )\n",
    "  print(f\"{name} documents {len(dataset)}\")\n",
    "  return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9sJNGKMG_x2",
    "outputId": "c2a12379-d366-437b-93dc-a502606b2ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train documents 7270\n",
      "Test documents 3463\n",
      "Validation documents 808\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = dataloader(train_inputs, train_masks, train_labels, \"Train\")\n",
    "test_dataloader = dataloader(test_data, test_masks, test_labels, \"Test\")\n",
    "val_dataloader = dataloader(validation_inputs, validation_masks, validation_labels, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "0ZyEtnm6VSuT"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EURfgE8lL-su"
   },
   "source": [
    "### Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E527GymlMHGh"
   },
   "source": [
    "\"bert-base-uncased\" = the 12-layer BERT model, with an uncased vocab.se the 12-layer BERT model, with an uncased vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "NkNa6RvNMCsS"
   },
   "outputs": [],
   "source": [
    "BERTMODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSSp-81yL643",
    "outputId": "38981883-6b09-4351-a58e-92ec1ab2907f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    BERTMODEL, \n",
    "    num_labels = 2, # Binary classification   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRS0T3kZNQ0P"
   },
   "source": [
    "To run this model on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3gULeMNpaFY",
    "outputId": "4f65d9ad-8d84-4cc9-b474-3986eaff4b87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyPv7zDZPDjC"
   },
   "source": [
    "Define optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "lsNN5OG0NRyK"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "zS0N_idCQEgT"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "TSSKCkbxTnOY"
   },
   "outputs": [],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avB8dJweQuSF",
    "outputId": "dabea4b8-cada-4736-e6d7-34f41f088d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      " \t Average training loss: 0.08\n",
      "  Accuracy: 0.92\n",
      "  Validation Loss: 0.31\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      " \t Average training loss: 0.05\n",
      "  Accuracy: 0.93\n",
      "  Validation Loss: 0.34\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device) #batch[0] - input_ids\n",
    "        b_input_mask = batch[1].to(device) #batch[1] - attention_masks\n",
    "        b_labels = batch[2].to(device) #batch[2] - labels\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        model.zero_grad() \n",
    "\n",
    "        # Forward pass (for evaluate the model on this training batch)\n",
    "        model1 = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels) \n",
    "        loss = model1.loss\n",
    "        logits = model1.logits\n",
    "        \n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()       \n",
    "\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)    \n",
    "\n",
    "    print(\"\\n \\t Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation PHASE \n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model2 = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss = model2.loss\n",
    "            logits = model2.logits\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "nKCjAA4nQuVP",
    "outputId": "c6a7ae34-6bf1-42b2-9af4-5389b7ef698e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.311675</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049177</td>\n",
       "      <td>0.335323</td>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur.\n",
       "epoch                                           \n",
       "1           0.081333     0.311675       0.921875\n",
       "2           0.049177     0.335323       0.925481"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 6)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqvqMcu6XrX1"
   },
   "source": [
    "Evaluation on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "mVNTqe5iQucc"
   },
   "outputs": [],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  prediction = np.argmax(logits, axis=1)\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  for i in prediction:\n",
    "    predictions.append(i)\n",
    "  for i in label_ids:\n",
    "    true_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "8AvSey-PY6E1"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(real_v, pred_v):\n",
    "    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(real_v, pred_v))\n",
    "    cm = confusion_matrix(real_v, pred_v)\n",
    "    print (f\"Confusion matrix \\n {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_MDebtnY_DM",
    "outputId": "8e70f120-04e0-4271-b022-b65adbb9d7fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.9200115506786024\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2754\n",
      "           1       0.81      0.80      0.80       709\n",
      "\n",
      "    accuracy                           0.92      3463\n",
      "   macro avg       0.88      0.87      0.88      3463\n",
      "weighted avg       0.92      0.92      0.92      3463\n",
      "\n",
      "Confusion matrix \n",
      " [[2621  133]\n",
      " [ 144  565]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "TVtUr-zXfEdx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task5 - Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
