{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide Training - Test (70-30)\n",
    "- Encoding test:\n",
    "                 0: negative\n",
    "                 1: neutral\n",
    "                 2: positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>length_text</th>\n",
       "      <th>not_tag_text</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negative_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>@mention @mention say</td>\n",
       "      <td>22</td>\n",
       "      <td>say</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>@mention plus add commercial experience tacky</td>\n",
       "      <td>46</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>@mention today must mean need take another trip</td>\n",
       "      <td>48</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>@mention really aggressive blast obnoxious ent...</td>\n",
       "      <td>88</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bad Flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>@mention really big bad thing</td>\n",
       "      <td>30</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>negative</td>\n",
       "      <td>Can't Tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                   preprocessed_text  length_text  \\\n",
       "0                             @mention @mention say            22   \n",
       "1     @mention plus add commercial experience tacky            46   \n",
       "2   @mention today must mean need take another trip            48   \n",
       "3  @mention really aggressive blast obnoxious ent...           88   \n",
       "4                     @mention really big bad thing            30   \n",
       "\n",
       "                                        not_tag_text         airline  \\\n",
       "0                                               say   Virgin America   \n",
       "1              plus add commercial experience tacky   Virgin America   \n",
       "2            today must mean need take another trip   Virgin America   \n",
       "3   really aggressive blast obnoxious entertainme...  Virgin America   \n",
       "4                              really big bad thing   Virgin America   \n",
       "\n",
       "  airline_sentiment negative_reason  \n",
       "0           neutral             NaN  \n",
       "1          positive             NaN  \n",
       "2           neutral             NaN  \n",
       "3          negative      Bad Flight  \n",
       "4          negative      Can't Tell  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "X = df['preprocessed_text']\n",
    "y = encoder.fit_transform(df[\"airline_sentiment\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248, 10248, 4392, 4392)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(real_v, pred_v):\n",
    "    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(real_v, pred_v))\n",
    "    cm = confusion_matrix(real_v, pred_v)\n",
    "    print (f\"Confusion matrix \\n {cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Vectorization\n",
    "- Fit to learn a vocabulary dictionary of all tokens in the raw documents\n",
    "- Transform documents to document-term matrix\n",
    "- Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 59)\t1\n",
      "  (0, 446)\t1\n",
      "  (0, 1107)\t1\n",
      "  (0, 1878)\t1\n",
      "  (0, 2209)\t1\n",
      "  (0, 2576)\t1\n",
      "  (0, 2598)\t1\n",
      "  (0, 2647)\t1\n",
      "  (0, 2794)\t1\n",
      "  (0, 3255)\t1\n",
      "  (0, 3516)\t1\n",
      "  (0, 3704)\t1\n",
      "  (0, 3761)\t1\n",
      "  (0, 3769)\t1\n",
      "  (0, 3827)\t1\n",
      "  (1, 1366)\t1\n",
      "  (1, 1380)\t1\n",
      "  (1, 1878)\t2\n",
      "  (1, 3611)\t1\n",
      "  (1, 3614)\t1\n",
      "  (2, 1878)\t1\n",
      "  (2, 2235)\t1\n",
      "  (2, 3713)\t1\n",
      "  (3, 667)\t1\n",
      "  (3, 674)\t1\n",
      "  :\t:\n",
      "  (10246, 383)\t1\n",
      "  (10246, 627)\t1\n",
      "  (10246, 971)\t1\n",
      "  (10246, 972)\t1\n",
      "  (10246, 1085)\t1\n",
      "  (10246, 1366)\t1\n",
      "  (10246, 1375)\t1\n",
      "  (10246, 1398)\t1\n",
      "  (10246, 1878)\t1\n",
      "  (10246, 2365)\t1\n",
      "  (10246, 2375)\t1\n",
      "  (10246, 2434)\t2\n",
      "  (10246, 2449)\t1\n",
      "  (10246, 2492)\t1\n",
      "  (10246, 2598)\t1\n",
      "  (10246, 2599)\t1\n",
      "  (10247, 125)\t1\n",
      "  (10247, 562)\t1\n",
      "  (10247, 1878)\t1\n",
      "  (10247, 1949)\t1\n",
      "  (10247, 2721)\t1\n",
      "  (10247, 2733)\t1\n",
      "  (10247, 3157)\t1\n",
      "  (10247, 3611)\t1\n",
      "  (10247, 3759)\t1\n"
     ]
    }
   ],
   "source": [
    "vect.fit(X_train)\n",
    "X_train_vect = vect.transform(X_train)\n",
    "print(X_train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 191)\t1\n",
      "  (0, 446)\t1\n",
      "  (0, 449)\t1\n",
      "  (0, 971)\t1\n",
      "  (0, 978)\t1\n",
      "  (0, 1068)\t1\n",
      "  (0, 1366)\t1\n",
      "  (0, 1398)\t1\n",
      "  (0, 1405)\t1\n",
      "  (0, 1878)\t1\n",
      "  (0, 2094)\t1\n",
      "  (0, 2365)\t2\n",
      "  (0, 2370)\t1\n",
      "  (0, 2375)\t1\n",
      "  (0, 2655)\t1\n",
      "  (0, 3200)\t1\n",
      "  (0, 3555)\t1\n",
      "  (1, 344)\t1\n",
      "  (1, 345)\t1\n",
      "  (1, 481)\t2\n",
      "  (1, 814)\t1\n",
      "  (1, 1172)\t1\n",
      "  (1, 1336)\t1\n",
      "  (1, 1874)\t1\n",
      "  (1, 1878)\t1\n",
      "  :\t:\n",
      "  (4389, 1993)\t1\n",
      "  (4389, 3327)\t1\n",
      "  (4389, 3588)\t1\n",
      "  (4390, 803)\t2\n",
      "  (4390, 804)\t1\n",
      "  (4390, 1349)\t1\n",
      "  (4390, 1635)\t1\n",
      "  (4390, 1878)\t1\n",
      "  (4390, 2018)\t1\n",
      "  (4390, 3377)\t1\n",
      "  (4391, 55)\t1\n",
      "  (4391, 794)\t1\n",
      "  (4391, 978)\t1\n",
      "  (4391, 1035)\t1\n",
      "  (4391, 1262)\t1\n",
      "  (4391, 1878)\t1\n",
      "  (4391, 2434)\t2\n",
      "  (4391, 2567)\t1\n",
      "  (4391, 2844)\t1\n",
      "  (4391, 2895)\t1\n",
      "  (4391, 2914)\t1\n",
      "  (4391, 3187)\t1\n",
      "  (4391, 3605)\t1\n",
      "  (4391, 3719)\t1\n",
      "  (4391, 3720)\t1\n"
     ]
    }
   ],
   "source": [
    "X_test_vect =vect.transform(X_test)\n",
    "print(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Array mapping from feature integer indices to feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acceptable'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Example of simple SVM\n",
    "Linear SVC with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "learner = LinearSVC()\n",
    "classifier = learner.fit(X_train_vect, y_train)\n",
    "predictions = classifier.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7556921675774135\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      2753\n",
      "           1       0.56      0.54      0.55       930\n",
      "           2       0.70      0.65      0.67       709\n",
      "\n",
      "    accuracy                           0.76      4392\n",
      "   macro avg       0.69      0.68      0.69      4392\n",
      "weighted avg       0.75      0.76      0.75      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2359  283  111]\n",
      " [ 340  499   91]\n",
      " [ 132  116  461]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Example of SVM with TF-IDF\n",
    "TF-IDF for feature extraction <br>\n",
    "Linear SVC with default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5,ngram_range=(1, 2))\n",
    "vectorizer.fit(X_train)\n",
    "training_features = vectorizer.transform(X_train)\n",
    "test_features =vectorizer.transform(X_test)\n",
    "\n",
    "learner = LinearSVC()\n",
    "classifier = learner.fit(training_features, y_train)\n",
    "predictions = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7750455373406193\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      2753\n",
      "           1       0.61      0.49      0.55       930\n",
      "           2       0.75      0.65      0.70       709\n",
      "\n",
      "    accuracy                           0.78      4392\n",
      "   macro avg       0.73      0.68      0.70      4392\n",
      "weighted avg       0.77      0.78      0.77      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2481  197   75]\n",
      " [ 390  459   81]\n",
      " [ 153   92  464]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Example of SVM with chi2\n",
    "Use chi2 for feature selection: select features according to k highest score   <br>\n",
    "Linear SVC with default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "sel = SelectKBest(chi2, k=500)  \n",
    "sel.fit(X_train_vect,y_train)\n",
    "X_train_sel = sel.transform(X_train_vect)\n",
    "X_test_sel = sel.transform(X_test_vect)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm_clf = svm.fit(X_train_sel,y_train)\n",
    "predictions = svm_clf.predict(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7661657559198543\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86      2753\n",
      "           1       0.60      0.48      0.53       930\n",
      "           2       0.73      0.62      0.67       709\n",
      "\n",
      "    accuracy                           0.77      4392\n",
      "   macro avg       0.71      0.67      0.69      4392\n",
      "weighted avg       0.75      0.77      0.76      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2481  193   79]\n",
      " [ 404  443   83]\n",
      " [ 162  106  441]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Example of SVM with chi2 + TFIDF\n",
    "Use chi2 for feature selection: select features according to k highest score   <br>\n",
    "TFIDF transformer <br>\n",
    "Linear SVC with default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=500)  \n",
    "sel.fit(X_train_vect,y_train)\n",
    "X_train_sel = sel.transform(X_train_vect)\n",
    "X_test_sel = sel.transform(X_test_vect)\n",
    "\n",
    "tfidf = TfidfTransformer()  # weighting\n",
    "tfidf.fit(X_train_sel)\n",
    "X_train_vec_bestK = tfidf.transform(X_train_sel)\n",
    "X_test_vec_bestK =tfidf.transform(X_test_sel)\n",
    "\n",
    "learner = LinearSVC()  # linear svm with default parameters\n",
    "classifier = learner.fit(X_train_vec_bestK, y_train)\n",
    "predictions = classifier.predict(X_test_vec_bestK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7650273224043715\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      2753\n",
      "           1       0.61      0.45      0.52       930\n",
      "           2       0.72      0.63      0.67       709\n",
      "\n",
      "    accuracy                           0.77      4392\n",
      "   macro avg       0.71      0.66      0.68      4392\n",
      "weighted avg       0.75      0.77      0.75      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2498  176   79]\n",
      " [ 419  416   95]\n",
      " [ 170   93  446]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtGridSearch(X_train, X_test, y_train, y_test, scores, model, tuned_parameters):\n",
    "    optimals = {}\n",
    "    for score in scores:\n",
    "        print(\"------- Score = \" + str(score) + \" ------- \\n\")\n",
    "        \n",
    "        k_fold = StratifiedKFold(n_splits=3, random_state=42)\n",
    "        print(\"> Fold = \" + str(k_fold) + \"\\n\")\n",
    "        \n",
    "        clf = GridSearchCV(model, tuned_parameters, error_score='raise', cv=k_fold, scoring = score, return_train_score=True)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"> Best Parameter set: \\n\")\n",
    "        best = clf.best_params_\n",
    "        print(best)\n",
    "        \n",
    "        print(\"\\n> Grid scores:\\n\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        \n",
    "        print(\"...........RESULTS FOR TRAINING.........\")\n",
    "        print(\"........................................\")\n",
    "        means = clf.cv_results_['mean_train_score']\n",
    "        stds = clf.cv_results_['std_train_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))        \n",
    "        \n",
    "        print(\"____________________________________________\")\n",
    "        \n",
    "        optimals[score] = best\n",
    "    return optimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - LinearSVC + gridsearch tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Score = f1_macro ------- \n",
      "\n",
      "> Fold = StratifiedKFold(n_splits=3, random_state=42, shuffle=False)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Best Parameter set: \n",
      "\n",
      "{'selbestk__k': 800, 'svc__C': 1}\n",
      "\n",
      "> Grid scores:\n",
      "\n",
      "...........RESULTS FOR TRAINING.........\n",
      "........................................\n",
      "0.554 (+/-0.008) for {'selbestk__k': 200, 'svc__C': 0.01}\n",
      "0.646 (+/-0.038) for {'selbestk__k': 200, 'svc__C': 0.1}\n",
      "0.684 (+/-0.000) for {'selbestk__k': 200, 'svc__C': 1}\n",
      "0.685 (+/-0.001) for {'selbestk__k': 200, 'svc__C': 10}\n",
      "0.683 (+/-0.009) for {'selbestk__k': 200, 'svc__C': 100}\n",
      "0.546 (+/-0.009) for {'selbestk__k': 300, 'svc__C': 0.01}\n",
      "0.696 (+/-0.006) for {'selbestk__k': 300, 'svc__C': 0.1}\n",
      "0.716 (+/-0.002) for {'selbestk__k': 300, 'svc__C': 1}\n",
      "0.719 (+/-0.003) for {'selbestk__k': 300, 'svc__C': 10}\n",
      "0.718 (+/-0.006) for {'selbestk__k': 300, 'svc__C': 100}\n",
      "0.529 (+/-0.009) for {'selbestk__k': 500, 'svc__C': 0.01}\n",
      "0.719 (+/-0.005) for {'selbestk__k': 500, 'svc__C': 0.1}\n",
      "0.749 (+/-0.008) for {'selbestk__k': 500, 'svc__C': 1}\n",
      "0.754 (+/-0.010) for {'selbestk__k': 500, 'svc__C': 10}\n",
      "0.753 (+/-0.011) for {'selbestk__k': 500, 'svc__C': 100}\n",
      "0.502 (+/-0.009) for {'selbestk__k': 800, 'svc__C': 0.01}\n",
      "0.741 (+/-0.010) for {'selbestk__k': 800, 'svc__C': 0.1}\n",
      "0.790 (+/-0.013) for {'selbestk__k': 800, 'svc__C': 1}\n",
      "0.799 (+/-0.016) for {'selbestk__k': 800, 'svc__C': 10}\n",
      "0.801 (+/-0.017) for {'selbestk__k': 800, 'svc__C': 100}\n",
      "0.489 (+/-0.008) for {'selbestk__k': 1000, 'svc__C': 0.01}\n",
      "0.748 (+/-0.008) for {'selbestk__k': 1000, 'svc__C': 0.1}\n",
      "0.809 (+/-0.008) for {'selbestk__k': 1000, 'svc__C': 1}\n",
      "0.824 (+/-0.013) for {'selbestk__k': 1000, 'svc__C': 10}\n",
      "0.827 (+/-0.013) for {'selbestk__k': 1000, 'svc__C': 100}\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = [\"f1_macro\"]\n",
    "\n",
    "params = {\"selbestk__k\": [200, 300, 500, 800, 1000],\n",
    "          \"svc__C\": [.01, .1, 1, 10, 100]}\n",
    "\n",
    "clf = Pipeline([\n",
    "                (\"selbestk\", SelectKBest(score_func = chi2)),\n",
    "                (\"tfidf\", TfidfTransformer()),\n",
    "                (\"svc\", LinearSVC())\n",
    "                ])\n",
    "\n",
    "optimals = builtGridSearch(X_train_vect, X_test_vect, y_train, y_test, scores, clf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=optimals[\"f1_macro\"][\"selbestk__k\"])  \n",
    "sel.fit(X_train_vect,y_train)\n",
    "X_train_sel = sel.transform(X_train_vect)\n",
    "X_test_sel = sel.transform(X_test_vect)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(X_train_sel)\n",
    "X_train_vec_bestK = tfidf.transform(X_train_sel)\n",
    "X_test_vec_bestK =tfidf.transform(X_test_sel)\n",
    "\n",
    "learner = LinearSVC(C=optimals[\"f1_macro\"][\"svc__C\"])\n",
    "classifier = learner.fit(X_train_vec_bestK, y_train)\n",
    "predictions = classifier.predict(X_test_vec_bestK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7773224043715847\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      2753\n",
      "           1       0.63      0.49      0.55       930\n",
      "           2       0.75      0.65      0.69       709\n",
      "\n",
      "    accuracy                           0.78      4392\n",
      "   macro avg       0.73      0.68      0.70      4392\n",
      "weighted avg       0.77      0.78      0.77      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2499  177   77]\n",
      " [ 396  456   78]\n",
      " [ 157   93  459]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_macro': {'selbestk__k': 800, 'svc__C': 1}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - SVC + gridsearch tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Score = f1_macro ------- \n",
      "\n",
      "> Fold = StratifiedKFold(n_splits=3, random_state=42, shuffle=False)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federica\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Best Parameter set: \n",
      "\n",
      "{'selbestk__k': 1000, 'svc__C': 1}\n",
      "\n",
      "> Grid scores:\n",
      "\n",
      "...........RESULTS FOR TRAINING.........\n",
      "........................................\n",
      "0.300 (+/-0.005) for {'selbestk__k': 200, 'svc__C': 0.01}\n",
      "0.581 (+/-0.048) for {'selbestk__k': 200, 'svc__C': 0.1}\n",
      "0.729 (+/-0.010) for {'selbestk__k': 200, 'svc__C': 1}\n",
      "0.831 (+/-0.014) for {'selbestk__k': 200, 'svc__C': 10}\n",
      "0.843 (+/-0.017) for {'selbestk__k': 200, 'svc__C': 100}\n",
      "0.285 (+/-0.040) for {'selbestk__k': 300, 'svc__C': 0.01}\n",
      "0.562 (+/-0.007) for {'selbestk__k': 300, 'svc__C': 0.1}\n",
      "0.771 (+/-0.011) for {'selbestk__k': 300, 'svc__C': 1}\n",
      "0.885 (+/-0.012) for {'selbestk__k': 300, 'svc__C': 10}\n",
      "0.894 (+/-0.010) for {'selbestk__k': 300, 'svc__C': 100}\n",
      "0.257 (+/-0.000) for {'selbestk__k': 500, 'svc__C': 0.01}\n",
      "0.497 (+/-0.037) for {'selbestk__k': 500, 'svc__C': 0.1}\n",
      "0.816 (+/-0.009) for {'selbestk__k': 500, 'svc__C': 1}\n",
      "0.937 (+/-0.008) for {'selbestk__k': 500, 'svc__C': 10}\n",
      "0.940 (+/-0.009) for {'selbestk__k': 500, 'svc__C': 100}\n",
      "0.257 (+/-0.000) for {'selbestk__k': 800, 'svc__C': 0.01}\n",
      "0.430 (+/-0.020) for {'selbestk__k': 800, 'svc__C': 0.1}\n",
      "0.864 (+/-0.010) for {'selbestk__k': 800, 'svc__C': 1}\n",
      "0.965 (+/-0.007) for {'selbestk__k': 800, 'svc__C': 10}\n",
      "0.967 (+/-0.007) for {'selbestk__k': 800, 'svc__C': 100}\n",
      "0.257 (+/-0.000) for {'selbestk__k': 1000, 'svc__C': 0.01}\n",
      "0.417 (+/-0.018) for {'selbestk__k': 1000, 'svc__C': 0.1}\n",
      "0.879 (+/-0.009) for {'selbestk__k': 1000, 'svc__C': 1}\n",
      "0.974 (+/-0.003) for {'selbestk__k': 1000, 'svc__C': 10}\n",
      "0.975 (+/-0.004) for {'selbestk__k': 1000, 'svc__C': 100}\n",
      "____________________________________________\n"
     ]
    }
   ],
   "source": [
    "scores = [\"f1_macro\"]\n",
    "\n",
    "params = {\"selbestk__k\": [200, 300, 500, 800, 1000],\n",
    "          \"svc__C\": [.01, .1, 1, 10, 100]}\n",
    "\n",
    "clf = Pipeline([\n",
    "                (\"selbestk\", SelectKBest(score_func = chi2)),\n",
    "                (\"tfidf\", TfidfTransformer()),\n",
    "                (\"svc\", SVC())\n",
    "                ])\n",
    "\n",
    "optimals = builtGridSearch(X_train_vect, X_test_vect, y_train, y_test, scores, clf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=optimals[\"f1_macro\"][\"selbestk__k\"])  \n",
    "sel.fit(X_train_vect,y_train)\n",
    "X_train_sel = sel.transform(X_train_vect)\n",
    "X_test_sel = sel.transform(X_test_vect)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(X_train_sel)\n",
    "X_train_vec_bestK = tfidf.transform(X_train_sel)\n",
    "X_test_vec_bestK =tfidf.transform(X_test_sel)\n",
    "\n",
    "learner = SVC(C = optimals[\"f1_macro\"][\"svc__C\"])\n",
    "classifier = learner.fit(X_train_vec_bestK, y_train)\n",
    "predictions = classifier.predict(X_test_vec_bestK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sore: 0.7766393442622951\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      2753\n",
      "           1       0.66      0.46      0.54       930\n",
      "           2       0.76      0.62      0.68       709\n",
      "\n",
      "    accuracy                           0.78      4392\n",
      "   macro avg       0.74      0.67      0.70      4392\n",
      "weighted avg       0.77      0.78      0.76      4392\n",
      "\n",
      "Confusion matrix \n",
      " [[2543  143   67]\n",
      " [ 431  430   69]\n",
      " [ 194   77  438]]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
